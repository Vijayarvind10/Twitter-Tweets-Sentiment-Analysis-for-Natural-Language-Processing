{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daa82242-8d53-4722-9ad8-5d1e6d85bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Embedding, Dense, GlobalMaxPool1D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers import LeakyReLU\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a3294e-89e4-4226-a23e-898ae03d6873",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ee0701-9a9e-4c94-ba07-9af2ceaa5033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c701ae-83e7-455f-93a6-8cd016926fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d111851-097c-4d24-b254-a640902fc945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497cfe11-8a25-4edb-a25f-a769e3f00a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'neutral', 1: 'negative', 2: 'positive'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['label_id'] = dataset['sentiment'].factorize()[0]\n",
    "cat_id = dataset[['sentiment', 'label_id']].drop_duplicates().sort_values('label_id')\n",
    "cat_to_id = dict(cat_id.values)\n",
    "id_to_cat = dict(cat_id[['label_id', 'sentiment']].values)\n",
    "\n",
    "#show data id_to_kategori\n",
    "id_to_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7044123-b902-4c57-94dd-d4cf7854bb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  label_id  \n",
       "0  I`d have responded, if I were going   neutral         0  \n",
       "1                             Sooo SAD  negative         1  \n",
       "2                          bullying me  negative         1  \n",
       "3                       leave me alone  negative         1  \n",
       "4                        Sons of ****,  negative         1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f07313d0-d89f-4023-b08b-b32b95d1f436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57284b7-10cb-4d77-b858-5b86ab5954e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dataset['label_id'].values\n",
    "text = dataset['selected_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de055ee1-e678-4478-a0ce-27ad556e054a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d6b24fb-3827-48eb-afbb-e69808d6b1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I`d have responded, if I were going' 'Sooo SAD' 'bullying me' ...\n",
      " 'Yay good for both of you.' 'But it was worth it  ****.'\n",
      " 'All this flirting going on - The ATG smiles. Yay.  ((hugs)']\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c04932e6-755e-4ea1-9e5e-05babb0754f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxfeatures = 10000\n",
    "tokenizer = Tokenizer(num_words = maxfeatures)\n",
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8f57fc4-74ac-4be0-8bee-7329c1cdac3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "maxseqlen = max([len(i.split()) for i in text])\n",
    "print(maxseqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "398a71d4-89e4-4d31-9ea0-f4ff6f48c77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Independent variable ['text']: (27480, 33)\n",
      "Shape of Dependent variable ['label']: (27480, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "X = tokenizer.texts_to_sequences(text)\n",
    "X = pad_sequences(X, maxseqlen)\n",
    "y = to_categorical(label, num_classes = 3)\n",
    "\n",
    "print(\"Shape of Independent variable ['text']:\", X.shape)\n",
    "print(\"Shape of Dependent variable ['label']:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d2ef582-24ed-49bd-a3e2-70c5d7e2cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21984, 33) (21984, 3)\n",
      "(5496, 33) (5496, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(Xtrain.shape, ytrain.shape)\n",
    "print(Xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0856e6d4-e8af-4b2a-abcd-b98510b9b7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 33, 128)           1280000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 33, 512)           1312768   \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 512)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 16)                0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,767,907\n",
      "Trainable params: 2,767,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = maxfeatures, output_dim = 128, input_length = maxseqlen))\n",
    "model.add(LSTM(512, return_sequences = True))\n",
    "model.add(GlobalMaxPool1D())\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(LeakyReLU(alpha = 0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(LeakyReLU(alpha = 0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(LeakyReLU(alpha = 0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(LeakyReLU(alpha = 0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(LeakyReLU(alpha = 0.3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = RMSprop(learning_rate = 0.0012, rho = 0.7, momentum = 0.5)\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "429058fc-6945-44a7-b28b-0a5d49d79318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# #declare checkpoint variable and early stopping to get best model\n",
    "# early_stop = EarlyStopping(monitor = 'val_accuracy', patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e4e9f16-1a9a-400f-9d94-fb6d0b9249be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir = 'logs',\n",
    "                                 histogram_freq = 0, \n",
    "                                 write_graph = True, \n",
    "                                 write_images = False,    \n",
    "                                 update_freq = 'epoch', \n",
    "                                 profile_batch = 2, \n",
    "                                 embeddings_freq = 0,    \n",
    "                                 embeddings_metadata = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c7741a5-43cc-4485-ad66-c98c3be0de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "198/198 [==============================] - 88s 434ms/step - loss: 0.7851 - accuracy: 0.6373 - val_loss: 0.5842 - val_accuracy: 0.7704\n",
      "Epoch 2/15\n",
      "198/198 [==============================] - 78s 392ms/step - loss: 0.5030 - accuracy: 0.8120 - val_loss: 0.4681 - val_accuracy: 0.8217\n",
      "Epoch 3/15\n",
      "198/198 [==============================] - 79s 399ms/step - loss: 0.4081 - accuracy: 0.8556 - val_loss: 0.4640 - val_accuracy: 0.8245\n",
      "Epoch 4/15\n",
      "198/198 [==============================] - 80s 406ms/step - loss: 0.3465 - accuracy: 0.8783 - val_loss: 0.4541 - val_accuracy: 0.8431\n",
      "Epoch 5/15\n",
      "198/198 [==============================] - 83s 418ms/step - loss: 0.3033 - accuracy: 0.8978 - val_loss: 0.5481 - val_accuracy: 0.8258\n",
      "Epoch 6/15\n",
      "198/198 [==============================] - 83s 418ms/step - loss: 0.2698 - accuracy: 0.9081 - val_loss: 0.4561 - val_accuracy: 0.8386\n",
      "Epoch 7/15\n",
      "198/198 [==============================] - 87s 440ms/step - loss: 0.2374 - accuracy: 0.9217 - val_loss: 0.4846 - val_accuracy: 0.8245\n",
      "Epoch 8/15\n",
      "198/198 [==============================] - 86s 436ms/step - loss: 0.2087 - accuracy: 0.9327 - val_loss: 0.4784 - val_accuracy: 0.8367\n",
      "Epoch 9/15\n",
      "198/198 [==============================] - 110s 555ms/step - loss: 0.1840 - accuracy: 0.9425 - val_loss: 0.5837 - val_accuracy: 0.8117\n",
      "Epoch 10/15\n",
      "198/198 [==============================] - 99s 503ms/step - loss: 0.1693 - accuracy: 0.9478 - val_loss: 0.5567 - val_accuracy: 0.8258\n",
      "Epoch 11/15\n",
      "198/198 [==============================] - 95s 478ms/step - loss: 0.1502 - accuracy: 0.9526 - val_loss: 0.6125 - val_accuracy: 0.8204\n",
      "Epoch 12/15\n",
      "198/198 [==============================] - 94s 473ms/step - loss: 0.1354 - accuracy: 0.9567 - val_loss: 0.6266 - val_accuracy: 0.8272\n",
      "Epoch 13/15\n",
      "198/198 [==============================] - 89s 448ms/step - loss: 0.1214 - accuracy: 0.9634 - val_loss: 0.6163 - val_accuracy: 0.8240\n",
      "Epoch 14/15\n",
      "198/198 [==============================] - 84s 424ms/step - loss: 0.1177 - accuracy: 0.9650 - val_loss: 0.6734 - val_accuracy: 0.8322\n",
      "Epoch 15/15\n",
      "198/198 [==============================] - 88s 444ms/step - loss: 0.1133 - accuracy: 0.9663 - val_loss: 0.8074 - val_accuracy: 0.8336\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Xtrain, ytrain,\n",
    "                    batch_size = 100, epochs = 15, shuffle = True,\n",
    "                    validation_split = 0.1, verbose = 1,\n",
    "                    callbacks = tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "981820f6-c8ce-411d-a415-3fc2ef9da085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5639297c-f982-450e-821a-ccf1e1168243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3184), started 0:29:17 ago. (Use '!kill 3184' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a647ac6930ea41f4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a647ac6930ea41f4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f950ba4-7a42-4370-a325-34545fb1cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#build eveluation function\n",
    "def evaluation(model, X, Y):\n",
    "  global Y_pred, Y_act\n",
    "  Y_pred = model.predict(X)\n",
    "  Y_pred_class = np.argmax(Y_pred, axis=1)\n",
    "  rounded_labels=np.argmax(Y, axis=1)\n",
    "  Y_act = rounded_labels\n",
    "  \n",
    "  accuracy = accuracy_score(Y_act, Y_pred_class)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b93a3fb-b31a-4973-a82c-56d6d9e6d8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 83.151 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluation(model, Xtest, ytest)\n",
    "print('accuracy: %.3f' % (accuracy * 100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0be2e377-76c9-491b-8384-4a99a9d2fbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1946  171  119]\n",
      " [ 274 1238   60]\n",
      " [ 214   88 1386]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neu       0.80      0.87      0.83      2236\n",
      "         neg       0.83      0.79      0.81      1572\n",
      "         pos       0.89      0.82      0.85      1688\n",
      "\n",
      "    accuracy                           0.83      5496\n",
      "   macro avg       0.84      0.83      0.83      5496\n",
      "weighted avg       0.83      0.83      0.83      5496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "target = ['neu', 'neg', 'pos']\n",
    "print(confusion_matrix(Y_act, np.argmax(Y_pred, axis=1)))\n",
    "print(classification_report(Y_act, np.argmax(Y_pred, axis = 1), target_names = target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
